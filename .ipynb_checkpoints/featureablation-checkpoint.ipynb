{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ca9df-c2b9-4069-b104-288ad7c097a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "import pandas as pd\n",
    "#from sae_lens.toolkit.neuronpedia_integration import get_feature_from_neuronpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e275371-dbfc-4da4-ac1a-94d2827329ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=\"cpu\")\n",
    "\n",
    "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
    "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
    "# We also return the feature sparsities which are stored in HF for convenience.\n",
    "sae, cfg_dict, sparsity = FreivaldsVerificationSAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",  # <- Release name\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",  # <- SAE id (not always a hook point!)\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c842fe4-2f38-4b6f-ade3-05f0005d00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def test_prompt_with_ablation(model, sae, prompt, answer, ablation_features):\n",
    "    def ablate_feature_hook(feature_activations, hook, feature_ids, position=None):\n",
    "        if position is None:\n",
    "            feature_activations[:, :, feature_ids] = 0\n",
    "        else:\n",
    "            feature_activations[:, position, feature_ids] = 0\n",
    "\n",
    "        return feature_activations\n",
    "\n",
    "    ablation_hook = partial(ablate_feature_hook, feature_ids=ablation_features)\n",
    "\n",
    "    model.add_sae(sae)\n",
    "    hook_point = sae.cfg.hook_name + \".hook_sae_acts_post\"\n",
    "    model.add_hook(hook_point, ablation_hook, \"fwd\")\n",
    "\n",
    "    test_prompt(prompt, answer, model)\n",
    "\n",
    "    model.reset_hooks()\n",
    "    model.reset_saes()\n",
    "\n",
    "\n",
    "# Example usage in a notebook:\n",
    "\n",
    "# Assume model and sae are already defined\n",
    "\n",
    "# Choose a feature to ablate\n",
    "\n",
    "model.reset_hooks(including_permanent=True)\n",
    "prompt = \"In the beginning, God created the heavens and the\"\n",
    "answer = \"earth\"\n",
    "test_prompt(prompt, answer, model)\n",
    "\n",
    "\n",
    "# Generate text with feature ablation\n",
    "print(\"Test Prompt with feature ablation and no error term\")\n",
    "ablation_feature = 16873  # Replace with any feature index you're interested in. We use the religion feature\n",
    "sae.use_error_term = False\n",
    "test_prompt_with_ablation(model, sae, prompt, answer, ablation_feature)\n",
    "\n",
    "print(\"Test Prompt with feature ablation and error term\")\n",
    "ablation_feature = 16873  # Replace with any feature index you're interested in. We use the religion feature\n",
    "sae.use_error_term = True\n",
    "test_prompt_with_ablation(model, sae, prompt, answer, ablation_feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
