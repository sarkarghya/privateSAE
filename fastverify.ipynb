{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c8cb0-0cae-4afc-afea-fc2f52f44636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "import pandas as pd\n",
    "#from sae_lens.toolkit.neuronpedia_integration import get_feature_from_neuronpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b2c9c-6f56-4520-adb9-83d7661816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=\"cpu\")\n",
    "\n",
    "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
    "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
    "# We also return the feature sparsities which are stored in HF for convenience.\n",
    "sae, cfg_dict, sparsity = FreivaldsVerificationSAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",  # <- Release name\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",  # <- SAE id (not always a hook point!)\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf921c7-5230-4f8f-8af7-d2e816048a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "prompt = \"Today is Sunday, tomorrow is\"\n",
    "tokens = model.to_tokens(prompt, prepend_bos=True)\n",
    "_, cache = model.run_with_cache_with_saes(\n",
    "    prompt, saes=[sae]\n",
    ")\n",
    "# _, cache = model.run_with_cache_with_saes(\n",
    "#     tokens, stop_at_layer=sae.cfg.hook_layer + 1, names_filter=[sae.cfg.hook_name]\n",
    "# )\n",
    "\n",
    "# print(cache)\n",
    "\n",
    "# blocks.7.hook_resid_pre.hook_sae_input\n",
    "# sae_in = cache[sae.cfg.hook_name + \".hook_sae_acts_post\"]  #[1, seq_len, d_in]\n",
    "\n",
    "# sae_in = cache[\"blocks.7.hook_resid_pre.hook_sae_input\"]\n",
    "# feature_acts = sae.encode(sae_in).squeeze(0)  #[seq_len, d_sae]\n",
    "\n",
    "sae_in_encoded = cache[\"blocks.7.hook_resid_pre.hook_sae_acts_post\"]\n",
    "feature_acts = sae_in_encoded.squeeze(0)  #[seq_len, d_sae]\n",
    "\n",
    "feature_list = [2592, 4445, 4663, 4733, 6531, 8179, 9566, 20927, 24185] \n",
    "\n",
    "feature_acts_sub = feature_acts[:, feature_list]  #[seq_len, len(feature_list)]\n",
    "\n",
    "# print(sae.W_dec)\n",
    "# print(\"Demo2, Feature activation: \", feature_acts.shape)\n",
    "# print(\"Demo2, Feature activation dived: \", feature_acts_sub.shape)\n",
    "\n",
    "def fast_verify(feature_acts_sub, num_trials=10, tol=1e-6):\n",
    "    seq_len, num_features = feature_acts_sub.shape\n",
    "    for _ in range(num_trials):\n",
    "        # Random binary vector (num_features x 1)\n",
    "        r = torch.randint(0, 2, (num_features, 1), dtype=feature_acts_sub.dtype, device=feature_acts_sub.device)\n",
    "        print(r)\n",
    "        # Matrix-vector multiplication: shape [seq_len, 1]\n",
    "        act_prod = feature_acts_sub @ r\n",
    "        print(act_prod)\n",
    "        # If any result is nonzero, a feature is active for at least one token\n",
    "        if torch.norm(act_prod) > tol:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "activated = fast_verify(feature_acts_sub)\n",
    "if activated:\n",
    "    print(\"At least one feature in the list is activated by the prompt!!!\")\n",
    "else:\n",
    "    print(\"None of the features in the list are activated by the prompt.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2b56d-70f1-41c2-a604-611249540022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"W_dec shape:\", sae.W_dec.shape)\n",
    "print(\"Max feature index:\", max(feature_list))\n",
    "print(\"d_sae (number of features):\", sae.cfg.d_sae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
